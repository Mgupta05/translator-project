{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9ea1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as text\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf1e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a1ba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohit\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "bpemb_en=BPEmb(lang=\"en\", dim=200, vs=100000)\n",
    "bpemb_pt=BPEmb(lang=\"pt\", dim=200, vs=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d37a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁stratford']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpemb_pt.encode(\"Stratford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53fa007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁oi', '▁como', '▁você', '▁está']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpemb_pt.encode(\"Oi como você está\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e3dc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids1=bpemb_en.encode_ids(\"vostalanj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac0b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2=bpemb_en.encode_ids(\"Soccer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111baf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97847, 8510, 99943]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f2885db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6528]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78bbca9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops._OptionsDataset"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']\n",
    "type(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cae7fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agora aqui temos imagens sendo extraídas em tempo real diretamente do feed ,\n",
      "os astrónomos acreditam que cada estrela da galáxia tem um planeta , e especulam que até um quinto deles tem um planeta do tipo da terra que poderá ter vida , mas ainda não vimos nenhum deles .\n",
      "agora : um , dois , três , vai .\n",
      "\n",
      "now here are live images being pulled straight from the feed .\n",
      "astronomers now believe that every star in the galaxy has a planet , and they speculate that up to one fifth of them have an earth-like planet that might be able to harbor life , but we have n't seen any of them .\n",
      "so : one , two , three , go .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "  for pt in pt_examples.numpy():\n",
    "    print(pt.decode('utf-8'))\n",
    "\n",
    "  print()\n",
    "\n",
    "  for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))\n",
    "    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c872b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_strings = [tf.compat.as_str_any(en_examples.numpy()) for tensor in en_examples] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "745f058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = bpemb_en.encode(list_of_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27456119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁',\n",
       "  '[',\n",
       "  'b',\n",
       "  \"'\",\n",
       "  'now',\n",
       "  '▁here',\n",
       "  '▁are',\n",
       "  '▁live',\n",
       "  '▁images',\n",
       "  '▁being',\n",
       "  '▁pulled',\n",
       "  '▁straight',\n",
       "  '▁from',\n",
       "  '▁the',\n",
       "  '▁feed',\n",
       "  '▁.',\n",
       "  \"'\",\n",
       "  '\\n',\n",
       "  '▁b',\n",
       "  '\"',\n",
       "  'astron',\n",
       "  'omers',\n",
       "  '▁now',\n",
       "  '▁believe',\n",
       "  '▁that',\n",
       "  '▁every',\n",
       "  '▁star',\n",
       "  '▁in',\n",
       "  '▁the',\n",
       "  '▁galaxy',\n",
       "  '▁has',\n",
       "  '▁a',\n",
       "  '▁planet',\n",
       "  '▁,',\n",
       "  '▁and',\n",
       "  '▁they',\n",
       "  '▁speculate',\n",
       "  '▁that',\n",
       "  '▁up',\n",
       "  '▁to',\n",
       "  '▁one',\n",
       "  '▁fifth',\n",
       "  '▁of',\n",
       "  '▁them',\n",
       "  '▁have',\n",
       "  '▁an',\n",
       "  '▁earth',\n",
       "  '-',\n",
       "  'like',\n",
       "  '▁planet',\n",
       "  '▁that',\n",
       "  '▁might',\n",
       "  '▁be',\n",
       "  '▁able',\n",
       "  '▁to',\n",
       "  '▁harbor',\n",
       "  '▁life',\n",
       "  '▁,',\n",
       "  '▁but',\n",
       "  '▁we',\n",
       "  '▁have',\n",
       "  '▁n',\n",
       "  \"'\",\n",
       "  't',\n",
       "  '▁seen',\n",
       "  '▁any',\n",
       "  '▁of',\n",
       "  '▁them',\n",
       "  '▁.\"',\n",
       "  '\\n',\n",
       "  '▁b',\n",
       "  \"'\",\n",
       "  'so',\n",
       "  '▁:',\n",
       "  '▁one',\n",
       "  '▁,',\n",
       "  '▁two',\n",
       "  '▁,',\n",
       "  '▁three',\n",
       "  '▁,',\n",
       "  '▁go',\n",
       "  '▁.',\n",
       "  \"'\",\n",
       "  ']'],\n",
       " ['▁',\n",
       "  '[',\n",
       "  'b',\n",
       "  \"'\",\n",
       "  'now',\n",
       "  '▁here',\n",
       "  '▁are',\n",
       "  '▁live',\n",
       "  '▁images',\n",
       "  '▁being',\n",
       "  '▁pulled',\n",
       "  '▁straight',\n",
       "  '▁from',\n",
       "  '▁the',\n",
       "  '▁feed',\n",
       "  '▁.',\n",
       "  \"'\",\n",
       "  '\\n',\n",
       "  '▁b',\n",
       "  '\"',\n",
       "  'astron',\n",
       "  'omers',\n",
       "  '▁now',\n",
       "  '▁believe',\n",
       "  '▁that',\n",
       "  '▁every',\n",
       "  '▁star',\n",
       "  '▁in',\n",
       "  '▁the',\n",
       "  '▁galaxy',\n",
       "  '▁has',\n",
       "  '▁a',\n",
       "  '▁planet',\n",
       "  '▁,',\n",
       "  '▁and',\n",
       "  '▁they',\n",
       "  '▁speculate',\n",
       "  '▁that',\n",
       "  '▁up',\n",
       "  '▁to',\n",
       "  '▁one',\n",
       "  '▁fifth',\n",
       "  '▁of',\n",
       "  '▁them',\n",
       "  '▁have',\n",
       "  '▁an',\n",
       "  '▁earth',\n",
       "  '-',\n",
       "  'like',\n",
       "  '▁planet',\n",
       "  '▁that',\n",
       "  '▁might',\n",
       "  '▁be',\n",
       "  '▁able',\n",
       "  '▁to',\n",
       "  '▁harbor',\n",
       "  '▁life',\n",
       "  '▁,',\n",
       "  '▁but',\n",
       "  '▁we',\n",
       "  '▁have',\n",
       "  '▁n',\n",
       "  \"'\",\n",
       "  't',\n",
       "  '▁seen',\n",
       "  '▁any',\n",
       "  '▁of',\n",
       "  '▁them',\n",
       "  '▁.\"',\n",
       "  '\\n',\n",
       "  '▁b',\n",
       "  \"'\",\n",
       "  'so',\n",
       "  '▁:',\n",
       "  '▁one',\n",
       "  '▁,',\n",
       "  '▁two',\n",
       "  '▁,',\n",
       "  '▁three',\n",
       "  '▁,',\n",
       "  '▁go',\n",
       "  '▁.',\n",
       "  \"'\",\n",
       "  ']'],\n",
       " ['▁',\n",
       "  '[',\n",
       "  'b',\n",
       "  \"'\",\n",
       "  'now',\n",
       "  '▁here',\n",
       "  '▁are',\n",
       "  '▁live',\n",
       "  '▁images',\n",
       "  '▁being',\n",
       "  '▁pulled',\n",
       "  '▁straight',\n",
       "  '▁from',\n",
       "  '▁the',\n",
       "  '▁feed',\n",
       "  '▁.',\n",
       "  \"'\",\n",
       "  '\\n',\n",
       "  '▁b',\n",
       "  '\"',\n",
       "  'astron',\n",
       "  'omers',\n",
       "  '▁now',\n",
       "  '▁believe',\n",
       "  '▁that',\n",
       "  '▁every',\n",
       "  '▁star',\n",
       "  '▁in',\n",
       "  '▁the',\n",
       "  '▁galaxy',\n",
       "  '▁has',\n",
       "  '▁a',\n",
       "  '▁planet',\n",
       "  '▁,',\n",
       "  '▁and',\n",
       "  '▁they',\n",
       "  '▁speculate',\n",
       "  '▁that',\n",
       "  '▁up',\n",
       "  '▁to',\n",
       "  '▁one',\n",
       "  '▁fifth',\n",
       "  '▁of',\n",
       "  '▁them',\n",
       "  '▁have',\n",
       "  '▁an',\n",
       "  '▁earth',\n",
       "  '-',\n",
       "  'like',\n",
       "  '▁planet',\n",
       "  '▁that',\n",
       "  '▁might',\n",
       "  '▁be',\n",
       "  '▁able',\n",
       "  '▁to',\n",
       "  '▁harbor',\n",
       "  '▁life',\n",
       "  '▁,',\n",
       "  '▁but',\n",
       "  '▁we',\n",
       "  '▁have',\n",
       "  '▁n',\n",
       "  \"'\",\n",
       "  't',\n",
       "  '▁seen',\n",
       "  '▁any',\n",
       "  '▁of',\n",
       "  '▁them',\n",
       "  '▁.\"',\n",
       "  '\\n',\n",
       "  '▁b',\n",
       "  \"'\",\n",
       "  'so',\n",
       "  '▁:',\n",
       "  '▁one',\n",
       "  '▁,',\n",
       "  '▁two',\n",
       "  '▁,',\n",
       "  '▁three',\n",
       "  '▁,',\n",
       "  '▁go',\n",
       "  '▁.',\n",
       "  \"'\",\n",
       "  ']']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9a5d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids3 = bpemb_en.encode_ids(list_of_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34652edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_string = \"but what if it were active ?\"\n",
    "ids=bpemb_en.encode(random_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90b132e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁but', '▁what', '▁if', '▁it', '▁were', '▁active', '▁?']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f136ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will setup an input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38e175f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to make tokenizer pairs for both and hence we will define functions to tokenize the same when we pass one pt string\n",
    "#and one english string as input\n",
    "\n",
    "def tokenize_pairs(pt, en):\n",
    "    list_of_strings1 =  [tf.compat.as_str_any(pt.numpy()) for tensor in pt]\n",
    "    pt = bpemb_pt.encode_ids(list_of_strings1)\n",
    "    pt = tf.convert_to_tensor(pt)\n",
    "    \n",
    "#to equalise length we will convert them from a ragged vector to a dense vector\n",
    "    pt = pt.to_tensor()\n",
    "    \n",
    "    list_of_strings2 =  [tf.compat.as_str_any(en.numpy()) for tensor in en]\n",
    "    \n",
    "    en = bpemb_pt.encode_ids(en)\n",
    "    en = tf.convert_to_tensor(en)\n",
    "    en = en.to_tensor()\n",
    "    \n",
    "    return pt, en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6685e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51f49f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly()\n",
    "@tf.function\n",
    "def make_batches(dataset):\n",
    "    dataset = dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85f9201e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    <ipython-input-25-1ec0473deae4>:4 make_batches  *\n        dataset = dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n    <ipython-input-19-218eb703c6e8>:5 tokenize_pairs  *\n        list_of_strings1 =  [tf.compat.as_str_any(pt.numpy()) for tensor in pt]\n    C:\\Users\\mohit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:520 __iter__\n        self._disallow_iteration()\n    C:\\Users\\mohit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:513 _disallow_iteration\n        self._disallow_when_autograph_enabled(\"iterating over `tf.Tensor`\")\n    C:\\Users\\mohit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:489 _disallow_when_autograph_enabled\n        raise errors.OperatorNotAllowedInGraphError(\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-617c044e8d1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_examples\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmake_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    <ipython-input-25-1ec0473deae4>:4 make_batches  *\n        dataset = dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n    <ipython-input-19-218eb703c6e8>:5 tokenize_pairs  *\n        list_of_strings1 =  [tf.compat.as_str_any(pt.numpy()) for tensor in pt]\n    C:\\Users\\mohit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:520 __iter__\n        self._disallow_iteration()\n    C:\\Users\\mohit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:513 _disallow_iteration\n        self._disallow_when_autograph_enabled(\"iterating over `tf.Tensor`\")\n    C:\\Users\\mohit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:489 _disallow_when_autograph_enabled\n        raise errors.OperatorNotAllowedInGraphError(\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n"
     ]
    }
   ],
   "source": [
    "train_examples= make_batches(train_examples)\n",
    "val_examples = make_batches(val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8cd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
